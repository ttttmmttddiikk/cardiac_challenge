{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\"data_hearts_dd_0p2\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_1_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_1_bcl_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_2_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_2_bcl_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_3_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_3_bcl_I\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the value range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_Y_Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_string_search = \"VmData\" #-93.086583844575 49.530741145564\n",
    "\n",
    "min_best = np.inf\n",
    "max_best = -np.inf\n",
    "\n",
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../intracardiac_dataset/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == first_string_search:\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_VmData_rawdata = np.load(\"../intracardiac_dataset/{0}/{1}\".format(dir_name,file_name))\n",
    "            #-----------------\n",
    "            #min, max\n",
    "            min = ndarray_VmData_rawdata.min()\n",
    "            max = ndarray_VmData_rawdata.max()\n",
    "            #-----------------\n",
    "            #check\n",
    "            if min<min_best:\n",
    "                min_best = min\n",
    "            if max_best<max:\n",
    "                max_best = max\n",
    "\n",
    "print(min_best, max_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_Y_Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_best = np.inf #0\n",
    "max_best = -np.inf #185\n",
    "\n",
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../intracardiac_dataset/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == \"VmData\":\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_VmData_rawdata = np.load(\"../intracardiac_dataset/{0}/{1}\".format(dir_name,file_name))\n",
    "            #activation_time\n",
    "            ndarray_VmData_activation_time = get_activation_time(Vm=ndarray_VmData_rawdata)\n",
    "            #-----------------\n",
    "            #min, max\n",
    "            min = ndarray_VmData_activation_time.min()\n",
    "            max = ndarray_VmData_activation_time.max()\n",
    "            #-----------------\n",
    "            #check\n",
    "            if min<min_best:\n",
    "                min_best = min\n",
    "            if max_best<max:\n",
    "                max_best = max\n",
    "\n",
    "print(min_best, max_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data_Y_Task3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "for cnt, dir_name in enumerate(dir_list):\n",
    "    os.makedirs(\"../VmData_Activation/{}\".format(dir_name), exist_ok=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make VmData_Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../intracardiac_dataset/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == \"VmData\":\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_VmData_rawdata = np.load(\"../intracardiac_dataset/{0}/{1}\".format(dir_name,file_name))\n",
    "            #activation_time\n",
    "            ndarray_VmData_activation_time = get_activation_time(Vm=ndarray_VmData_rawdata)\n",
    "            #calc /500 (std to train) : (0,185) ->(/185)-> (0,1)\n",
    "            ndarray_VmData_activation_time = ndarray_VmData_activation_time/185\n",
    "            #-----------------\n",
    "            #file_name_write\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            #-----------------\n",
    "            #save\n",
    "            np.save(\"../data_Y_Task3/{0}\".format(file_name_write), ndarray_VmData_activation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#ndarray_VmData_Activation = np.load('../data_Y_Task3/hearts_dd_0p2_geo_act_1_bcl_bcl.600.pattern.0.volunteer.v1.npy')\n",
    "ndarray_VmData_Activation = np.load('../data_Y_Task3/hearts_dd_0p2_volunteer.v1_pattern.0.npy')\n",
    "print(ndarray_VmData_Activation.shape)\n",
    "print(ndarray_VmData_Activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data_X, data_Y_Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../intracardiac_dataset/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing√ü\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #path_before\n",
    "        path_before = \"../intracardiac_dataset/{0}/{1}\".format(dir_name,file_name)\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == \"pECGData\":\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_pECGData_rawdata = np.load(\"../intracardiac_dataset/{0}/{1}\".format(dir_name,file_name))\n",
    "            #-----------------\n",
    "            #ndarray_pECGData_std & T\n",
    "            ndarray_pECGData_std = get_standard_leads(pECGnumpy=ndarray_pECGData_rawdata).T\n",
    "            #-----------------\n",
    "            #file_name_write\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            #-----------------\n",
    "            #save\n",
    "            np.save(\"../data_X/{0}\".format(file_name_write), ndarray_pECGData_std)\n",
    "        elif first_string == \"VmData\":\n",
    "            #-----------------\n",
    "            #file_name_write\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_VmData_rawdata = np.load(path_before)\n",
    "            #T\n",
    "            ndarray_VmData_rawdata = ndarray_VmData_rawdata.T\n",
    "            #calc /100 (std to train) : (-100,50) ->(+100)-> (0,150) >(/150)-> (0,1)\n",
    "            ndarray_VmData_rawdata = (ndarray_VmData_rawdata+100)/150\n",
    "            #save\n",
    "            np.save(\"../data_Y_Task4/{}\".format(file_name_write), ndarray_VmData_rawdata)\n",
    "        elif first_string == \".bash\":\n",
    "            pass\n",
    "        else:\n",
    "            print(first_string)\n",
    "            raise ValueError(\"error!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray_VmData_Activation = np.load('../data_X/hearts_dd_0p2_volunteer.v1_pattern.0.npy')\n",
    "print(ndarray_VmData_Activation.shape)\n",
    "print(ndarray_VmData_Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray_VmData_Activation = np.load('../data_Y_Task4/hearts_dd_0p2_volunteer.v1_pattern.0.npy')\n",
    "print(ndarray_VmData_Activation.shape)\n",
    "print(ndarray_VmData_Activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check # of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#-----------------\n",
    "#list_file_name\n",
    "list_file_name = os.listdir(\"../data_X\")\n",
    "print(len(list_file_name))\n",
    "\n",
    "#-----------------\n",
    "#list_file_name\n",
    "list_file_name = os.listdir(\"../data_Y_Task3\")\n",
    "print(len(list_file_name))\n",
    "\n",
    "\n",
    "#-----------------\n",
    "#list_file_name\n",
    "list_file_name = os.listdir(\"../data_Y_Task4\")\n",
    "print(len(list_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
