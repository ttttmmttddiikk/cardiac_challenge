{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run func_DL.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_task4(nn.Module):\n",
    "    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\n",
    "        super().__init__()\n",
    "        #-----------------------------------\n",
    "        #var\n",
    "        self.in_channels = in_channels\n",
    "        self.in_length = in_length\n",
    "        self.out_channels = out_channels\n",
    "        self.out_length = out_length\n",
    "        self.batch_size = batch_size\n",
    "        #-----------------------------------\n",
    "        #Conv1d\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        #https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        #conv1d_0\n",
    "        kernel_size_conv1d_0=2; stride_conv1d_0=1; padding_conv1d_0=1; dilation_conv1d_0=1; \n",
    "        self.in_channels_conv1d_0 = self.in_channels; self.in_length_conv1d_0 = self.in_length\n",
    "        self.out_channels_conv1d_0= 70; self.out_length_conv1d_0 = int((self.in_length_conv1d_0+2*padding_conv1d_0-dilation_conv1d_0*(kernel_size_conv1d_0-1)-1)/stride_conv1d_0+1)\n",
    "        #conv1d_1\n",
    "        kernel_size_conv1d_1=2; stride_conv1d_1=1; padding_conv1d_1=1; dilation_conv1d_1=1; \n",
    "        self.in_channels_conv1d_1 = self.out_channels_conv1d_0; self.in_length_conv1d_1 = self.out_length_conv1d_0\n",
    "        self.out_channels_conv1d_1= 70; self.out_length_conv1d_1= int((self.in_length_conv1d_1+2*padding_conv1d_1-dilation_conv1d_1*(kernel_size_conv1d_1-1)-1)/stride_conv1d_1+1)\n",
    "        #conv1d_2\n",
    "        kernel_size_conv1d_2=2; stride_conv1d_2=1; padding_conv1d_2=1; dilation_conv1d_2=1; \n",
    "        self.in_channels_conv1d_2 = self.out_channels_conv1d_1; self.in_length_conv1d_2 = self.out_length_conv1d_1\n",
    "        self.out_channels_conv1d_2= 70; self.out_length_conv1d_2= int((self.in_length_conv1d_2+2*padding_conv1d_2-dilation_conv1d_2*(kernel_size_conv1d_2-1)-1)/stride_conv1d_2+1)\n",
    "        #conv1d_3\n",
    "        kernel_size_conv1d_3=2; stride_conv1d_3=1; padding_conv1d_3=1; dilation_conv1d_3=1; \n",
    "        self.in_channels_conv1d_3 = self.out_channels_conv1d_2; self.in_length_conv1d_3 = self.out_length_conv1d_2\n",
    "        self.out_channels_conv1d_3= 70; self.out_length_conv1d_3= int((self.in_length_conv1d_3+2*padding_conv1d_3-dilation_conv1d_3*(kernel_size_conv1d_3-1)-1)/stride_conv1d_3+1)\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        self.in_channels_DNN = self.out_channels_conv1d_3*self.out_length_conv1d_3\n",
    "        self.inner_channels_DNN = 70\n",
    "        self.out_channels_DNN = self.out_channels*self.out_length\n",
    "\n",
    "        #-----------------------------------\n",
    "        #layer0\n",
    "        self.layer0 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            #conv1d_0\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_0, out_channels=self.out_channels_conv1d_0, kernel_size=kernel_size_conv1d_0, stride=stride_conv1d_0, padding=padding_conv1d_0, dilation=dilation_conv1d_0),\n",
    "            nn.BatchNorm1d(num_features=self.out_channels_conv1d_0),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #-----------------------------------\n",
    "            #conv1d_1\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_1, out_channels=self.out_channels_conv1d_1, kernel_size=kernel_size_conv1d_1, stride=stride_conv1d_1, padding=padding_conv1d_1, dilation=dilation_conv1d_1),\n",
    "            nn.BatchNorm1d(num_features=self.out_channels_conv1d_1),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #-----------------------------------\n",
    "            #conv1d_2\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_2, out_channels=self.out_channels_conv1d_2, kernel_size=kernel_size_conv1d_2, stride=stride_conv1d_2, padding=padding_conv1d_2, dilation=dilation_conv1d_2),\n",
    "            nn.BatchNorm1d(num_features=self.out_channels_conv1d_2),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #-----------------------------------\n",
    "            #conv1d_3\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_3, out_channels=self.out_channels_conv1d_3, kernel_size=kernel_size_conv1d_3, stride=stride_conv1d_3, padding=padding_conv1d_3, dilation=dilation_conv1d_3),\n",
    "            nn.BatchNorm1d(num_features=self.out_channels_conv1d_3),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        #-----------------------------------\n",
    "        #layer1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.Linear(self.in_channels_DNN, self.inner_channels_DNN),\n",
    "            nn.BatchNorm1d(num_features=self.inner_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            #-----------------------------------\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.inner_channels_DNN, self.inner_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            #-----------------------------------\n",
    "            nn.Linear(self.inner_channels_DNN, self.out_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),            \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):    \n",
    "        output0 = self.layer0(x).view(-1, self.in_channels_DNN)\n",
    "        output1 = self.layer1(output0).view(-1, self.out_channels, self.out_length)\n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class model_task4(nn.Module):\\n    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\\n        super().__init__()\\n        #-----------------------------------\\n        #var\\n        self.in_channels = in_channels\\n        self.in_length = in_length\\n        self.out_channels = out_channels\\n        self.out_length = out_length\\n        self.batch_size = batch_size\\n        #-----------------------------------\\n        #Conv1d\\n        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\\n        #https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\\n        #conv1d_0\\n        kernel_size_conv1d_0=5; stride_conv1d_0=2; padding_conv1d_0=1; dilation_conv1d_0=1; \\n        self.in_channels_conv1d_0 = self.in_channels; self.in_length_conv1d_0 = self.in_length\\n        self.out_channels_conv1d_0= 50; self.out_length_conv1d_0 = int((self.in_length_conv1d_0+2*padding_conv1d_0-dilation_conv1d_0*(kernel_size_conv1d_0-1)-1)/stride_conv1d_0+1)\\n        #conv1d_1\\n        kernel_size_conv1d_1=3; stride_conv1d_1=1; padding_conv1d_1=1; dilation_conv1d_1=1; \\n        self.in_channels_conv1d_1 = self.out_channels_conv1d_0; self.in_length_conv1d_1 = self.out_length_conv1d_0\\n        self.out_channels_conv1d_1= 30; self.out_length_conv1d_1= int((self.in_length_conv1d_1+2*padding_conv1d_1-dilation_conv1d_1*(kernel_size_conv1d_1-1)-1)/stride_conv1d_1+1)\\n        #conv1d_2\\n        kernel_size_conv1d_2=2; stride_conv1d_2=1; padding_conv1d_2=1; dilation_conv1d_2=1; \\n        self.in_channels_conv1d_2 = self.out_channels_conv1d_1; self.in_length_conv1d_2 = self.out_length_conv1d_1\\n        self.out_channels_conv1d_2= 10; self.out_length_conv1d_2= int((self.in_length_conv1d_2+2*padding_conv1d_2-dilation_conv1d_2*(kernel_size_conv1d_2-1)-1)/stride_conv1d_2+1)\\n        #-----------------------------------\\n        #DNN\\n        self.in_channels_DNN = self.out_channels_conv1d_2*self.out_length_conv1d_2\\n        self.inner_channels_DNN = 30\\n        self.out_channels_DNN = self.out_channels*self.out_length\\n\\n        #-----------------------------------\\n        #layer0\\n        self.layer0 = nn.Sequential(\\n            #-----------------------------------\\n            #conv1d_0\\n            nn.Conv1d(in_channels=self.in_channels_conv1d_0, out_channels=self.out_channels_conv1d_0, kernel_size=kernel_size_conv1d_0, stride=stride_conv1d_0, padding=padding_conv1d_0, dilation=dilation_conv1d_0),\\n            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_0),\\n            #nn.ReLU(),\\n            nn.Sigmoid(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n            #-----------------------------------\\n            #conv1d_1\\n            #nn.Dropout(p=0.2),\\n            nn.Conv1d(in_channels=self.in_channels_conv1d_1, out_channels=self.out_channels_conv1d_1, kernel_size=kernel_size_conv1d_1, stride=stride_conv1d_1, padding=padding_conv1d_1, dilation=dilation_conv1d_1),\\n            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_1),\\n            #nn.ReLU(),\\n            nn.Sigmoid(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n            #-----------------------------------\\n            #conv1d_2\\n            nn.Conv1d(in_channels=self.in_channels_conv1d_2, out_channels=self.out_channels_conv1d_2, kernel_size=kernel_size_conv1d_2, stride=stride_conv1d_2, padding=padding_conv1d_2, dilation=dilation_conv1d_2),\\n            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_2),\\n            #nn.ReLU(),\\n            nn.Sigmoid(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n        )\\n        #-----------------------------------\\n        #layer1\\n        self.layer1 = nn.Sequential(\\n            #-----------------------------------\\n            nn.Linear(self.in_channels_DNN, self.inner_channels_DNN),\\n            nn.BatchNorm1d(num_features=self.inner_channels_DNN),\\n            #nn.ReLU(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n            nn.Sigmoid(),\\n            #-----------------------------------\\n            nn.Dropout(p=0.2),\\n            nn.Linear(self.inner_channels_DNN, self.inner_channels_DNN),\\n            #nn.ReLU(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n            nn.Sigmoid(),\\n            #-----------------------------------\\n            nn.Linear(self.inner_channels_DNN, self.out_channels_DNN),\\n            #nn.ReLU(),\\n            nn.Sigmoid(),            \\n        )\\n\\n\\n    def forward(self, x):    \\n        output0 = self.layer0(x).view(-1, self.in_channels_DNN)\\n        output1 = self.layer1(output0).view(-1, self.out_channels, self.out_length)\\n        return output1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class model_task4(nn.Module):\n",
    "    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\n",
    "        super().__init__()\n",
    "        #-----------------------------------\n",
    "        #var\n",
    "        self.in_channels = in_channels\n",
    "        self.in_length = in_length\n",
    "        self.out_channels = out_channels\n",
    "        self.out_length = out_length\n",
    "        self.batch_size = batch_size\n",
    "        #-----------------------------------\n",
    "        #Conv1d\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        #https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        #conv1d_0\n",
    "        kernel_size_conv1d_0=5; stride_conv1d_0=2; padding_conv1d_0=1; dilation_conv1d_0=1; \n",
    "        self.in_channels_conv1d_0 = self.in_channels; self.in_length_conv1d_0 = self.in_length\n",
    "        self.out_channels_conv1d_0= 50; self.out_length_conv1d_0 = int((self.in_length_conv1d_0+2*padding_conv1d_0-dilation_conv1d_0*(kernel_size_conv1d_0-1)-1)/stride_conv1d_0+1)\n",
    "        #conv1d_1\n",
    "        kernel_size_conv1d_1=3; stride_conv1d_1=1; padding_conv1d_1=1; dilation_conv1d_1=1; \n",
    "        self.in_channels_conv1d_1 = self.out_channels_conv1d_0; self.in_length_conv1d_1 = self.out_length_conv1d_0\n",
    "        self.out_channels_conv1d_1= 30; self.out_length_conv1d_1= int((self.in_length_conv1d_1+2*padding_conv1d_1-dilation_conv1d_1*(kernel_size_conv1d_1-1)-1)/stride_conv1d_1+1)\n",
    "        #conv1d_2\n",
    "        kernel_size_conv1d_2=2; stride_conv1d_2=1; padding_conv1d_2=1; dilation_conv1d_2=1; \n",
    "        self.in_channels_conv1d_2 = self.out_channels_conv1d_1; self.in_length_conv1d_2 = self.out_length_conv1d_1\n",
    "        self.out_channels_conv1d_2= 10; self.out_length_conv1d_2= int((self.in_length_conv1d_2+2*padding_conv1d_2-dilation_conv1d_2*(kernel_size_conv1d_2-1)-1)/stride_conv1d_2+1)\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        self.in_channels_DNN = self.out_channels_conv1d_2*self.out_length_conv1d_2\n",
    "        self.inner_channels_DNN = 30\n",
    "        self.out_channels_DNN = self.out_channels*self.out_length\n",
    "\n",
    "        #-----------------------------------\n",
    "        #layer0\n",
    "        self.layer0 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            #conv1d_0\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_0, out_channels=self.out_channels_conv1d_0, kernel_size=kernel_size_conv1d_0, stride=stride_conv1d_0, padding=padding_conv1d_0, dilation=dilation_conv1d_0),\n",
    "            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_0),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #-----------------------------------\n",
    "            #conv1d_1\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_1, out_channels=self.out_channels_conv1d_1, kernel_size=kernel_size_conv1d_1, stride=stride_conv1d_1, padding=padding_conv1d_1, dilation=dilation_conv1d_1),\n",
    "            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_1),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #-----------------------------------\n",
    "            #conv1d_2\n",
    "            nn.Conv1d(in_channels=self.in_channels_conv1d_2, out_channels=self.out_channels_conv1d_2, kernel_size=kernel_size_conv1d_2, stride=stride_conv1d_2, padding=padding_conv1d_2, dilation=dilation_conv1d_2),\n",
    "            #nn.BatchNorm1d(num_features=self.out_channels_conv1d_2),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        #-----------------------------------\n",
    "        #layer1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.Linear(self.in_channels_DNN, self.inner_channels_DNN),\n",
    "            nn.BatchNorm1d(num_features=self.inner_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            #-----------------------------------\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.inner_channels_DNN, self.inner_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            #-----------------------------------\n",
    "            nn.Linear(self.inner_channels_DNN, self.out_channels_DNN),\n",
    "            #nn.ReLU(),\n",
    "            nn.Sigmoid(),            \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):    \n",
    "        output0 = self.layer0(x).view(-1, self.in_channels_DNN)\n",
    "        output1 = self.layer1(output0).view(-1, self.out_channels, self.out_length)\n",
    "        return output1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class model_1(nn.Module):\\n    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\\n        super().__init__()\\n        #-----------------------------------\\n        #var\\n        self.in_channels = in_channels\\n        self.in_length = in_length\\n        self.out_channels = out_channels\\n        self.out_length = out_length\\n        self.batch_size = batch_size\\n        #-----------------------------------\\n        #Conv1d\\n        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\\n        #https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\\n        self.in_channels_inner_0 = self.in_channels; self.in_length_inner_0 = self.in_length\\n        kernel_size=200; stride=50; padding=1; dilation=1; \\n        self.out_channels_inner_0 = 30; self.out_length_inner_0 = int((self.in_length_inner_0+2*padding-dilation*(kernel_size-1)-1)/stride+1)\\n        self.conv1d = nn.Conv1d(in_channels=self.in_channels_inner_0, out_channels=self.out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\\n        #-----------------------------------\\n        #DNN\\n        self.in_channels_inner_1 = self.out_channels_inner_0*self.out_length_inner_0\\n        self.out_channels_inner_1 = self.out_channels*self.out_length\\n\\n        #-----------------------------------\\n        #layer0\\n        self.layer0 = nn.Sequential(\\n            #-----------------------------------\\n            nn.Conv1d(in_channels=self.in_channels_inner_0, out_channels=self.out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation),\\n            nn.ReLU(),\\n            #nn.LeakyReLU(0.2, inplace=True),\\n            nn.BatchNorm1d(num_features=self.out_channels_inner_0),\\n        )\\n        #-----------------------------------\\n        #layer1\\n        self.layer1 = nn.Sequential(\\n            #-----------------------------------\\n            nn.Linear(self.in_channels_inner_1, self.out_channels_inner_1),\\n            #nn.ReLU(),\\n            #nn.Sigmoid(),\\n        )\\n\\n    def forward(self, x):\\n        #for i in range(5):\\n        output0 = self.layer0(x).view(-1, self.in_channels_inner_1)\\n        output1 = self.layer1(output0).view(-1, self.out_channels, self.out_length)\\n        return output1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class model_1(nn.Module):\n",
    "    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\n",
    "        super().__init__()\n",
    "        #-----------------------------------\n",
    "        #var\n",
    "        self.in_channels = in_channels\n",
    "        self.in_length = in_length\n",
    "        self.out_channels = out_channels\n",
    "        self.out_length = out_length\n",
    "        self.batch_size = batch_size\n",
    "        #-----------------------------------\n",
    "        #Conv1d\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        #https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "        self.in_channels_inner_0 = self.in_channels; self.in_length_inner_0 = self.in_length\n",
    "        kernel_size=200; stride=50; padding=1; dilation=1; \n",
    "        self.out_channels_inner_0 = 30; self.out_length_inner_0 = int((self.in_length_inner_0+2*padding-dilation*(kernel_size-1)-1)/stride+1)\n",
    "        self.conv1d = nn.Conv1d(in_channels=self.in_channels_inner_0, out_channels=self.out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        self.in_channels_inner_1 = self.out_channels_inner_0*self.out_length_inner_0\n",
    "        self.out_channels_inner_1 = self.out_channels*self.out_length\n",
    "\n",
    "        #-----------------------------------\n",
    "        #layer0\n",
    "        self.layer0 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.Conv1d(in_channels=self.in_channels_inner_0, out_channels=self.out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation),\n",
    "            nn.ReLU(),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm1d(num_features=self.out_channels_inner_0),\n",
    "        )\n",
    "        #-----------------------------------\n",
    "        #layer1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.Linear(self.in_channels_inner_1, self.out_channels_inner_1),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #for i in range(5):\n",
    "        output0 = self.layer0(x).view(-1, self.in_channels_inner_1)\n",
    "        output1 = self.layer1(output0).view(-1, self.out_channels, self.out_length)\n",
    "        return output1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class model_2(nn.Module):\\n    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\\n        super().__init__()\\n        #-----------------------------------\\n        #var\\n        self.in_channels = in_channels\\n        self.in_length = in_length\\n        self.out_channels = out_channels\\n        self.out_length = out_length\\n        self.batch_size = batch_size\\n        #-----------------------------------\\n        #DNN\\n        self.in_channels_inner_1 = self.in_channels*self.in_length\\n        self.out_channels_inner_1 = 30\\n        #-----------------------------------\\n        #DNN\\n        self.in_channels_inner_2 = self.out_channels_inner_1\\n        self.out_channels_inner_2 = self.out_channels*self.out_length\\n        #-----------------------------------\\n        #layer1\\n        self.layer1 = nn.Sequential(\\n            #-----------------------------------\\n            nn.BatchNorm1d(num_features=self.in_channels_inner_1),\\n            nn.Linear(self.in_channels_inner_1, self.out_channels_inner_1),\\n            nn.ReLU(),\\n            nn.Sigmoid(),\\n        )\\n        #-----------------------------------\\n        #layer2\\n        self.layer2 = nn.Sequential(\\n            #-----------------------------------\\n            nn.BatchNorm1d(num_features=self.in_channels_inner_2),\\n            nn.Linear(self.in_channels_inner_2, self.out_channels_inner_2),\\n            nn.ReLU(),\\n            nn.Sigmoid(),\\n        )\\n\\n    def forward(self, x):\\n        x = x.view(-1, self.in_channels_inner_1)\\n        output1 = self.layer1(x)\\n        output2 = self.layer2(output1)\\n        output2 = output2.view(-1, self.out_channels, self.out_length)\\n        return output2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class model_2(nn.Module):\n",
    "    def __init__(self, in_channels, in_length, out_channels, out_length, batch_size):\n",
    "        super().__init__()\n",
    "        #-----------------------------------\n",
    "        #var\n",
    "        self.in_channels = in_channels\n",
    "        self.in_length = in_length\n",
    "        self.out_channels = out_channels\n",
    "        self.out_length = out_length\n",
    "        self.batch_size = batch_size\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        self.in_channels_inner_1 = self.in_channels*self.in_length\n",
    "        self.out_channels_inner_1 = 30\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        self.in_channels_inner_2 = self.out_channels_inner_1\n",
    "        self.out_channels_inner_2 = self.out_channels*self.out_length\n",
    "        #-----------------------------------\n",
    "        #layer1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.BatchNorm1d(num_features=self.in_channels_inner_1),\n",
    "            nn.Linear(self.in_channels_inner_1, self.out_channels_inner_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        #-----------------------------------\n",
    "        #layer2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.BatchNorm1d(num_features=self.in_channels_inner_2),\n",
    "            nn.Linear(self.in_channels_inner_2, self.out_channels_inner_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.in_channels_inner_1)\n",
    "        output1 = self.layer1(x)\n",
    "        output2 = self.layer2(output1)\n",
    "        output2 = output2.view(-1, self.out_channels, self.out_length)\n",
    "        return output2\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#---------------------------------------------\n",
    "#var\n",
    "path_dir_X = \"../data_X\"\n",
    "path_dir_Y = \"../data_Y_Task4\"\n",
    "n_test = 0.2\n",
    "n_val = 100\n",
    "batch_size = 100\n",
    "\n",
    "#---------------------------------------------\n",
    "#instance\n",
    "dataset = CustomDataset(path_dir_X=path_dir_X, path_dir_Y=path_dir_Y, n_test=n_test, n_val=n_val, batch_size=batch_size)\n",
    "dataloder = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "#var (condition)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#----------------------------\n",
    "#var (train)\n",
    "num_epochs = 200\n",
    "n_print_train_result = 1\n",
    "val_flag = True\n",
    "\n",
    "#----------------------------\n",
    "#init (model)\n",
    "in_channels = dataset.return_shape_X()[0]\n",
    "in_length = dataset.return_shape_X()[1]\n",
    "out_channels = dataset.return_shape_Y()[0]\n",
    "out_length = dataset.return_shape_Y()[1]\n",
    "model = model_task4(in_channels, in_length, out_channels, out_length, batch_size).to(device)\n",
    "#init model weight\n",
    "model.apply(init_normal_dist)\n",
    "#----------------------------\n",
    "#init (optimizer, scheduler)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,50,100,300,500], gamma=0.9)\n",
    "#----------------------------\n",
    "#init (loss_func)\n",
    "#https://neptune.ai/blog/pytorch-loss-functions\n",
    "loss_func = nn.MSELoss()\n",
    "#loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, iter: 1, train_loss:  0.1168\n",
      "tensor(3.3495e-12)\n",
      "Epoch: 1, iter: 2, train_loss:  0.0530\n",
      "tensor(-2.7981e-13)\n",
      "Epoch: 1, iter: 3, train_loss:  0.0414\n",
      "tensor(3.7977e-13)\n",
      "Epoch: 1, iter: 4, train_loss:  0.0351\n",
      "tensor(2.9926e-13)\n",
      "Epoch: 1, iter: 5, train_loss:  0.0322\n",
      "tensor(1.7543e-13)\n",
      "Epoch: 1, iter: 6, train_loss:  0.0327\n",
      "tensor(2.5747e-13)\n",
      "Epoch: 1, iter: 7, train_loss:  0.0300\n",
      "tensor(2.6203e-13)\n",
      "Epoch: 1, iter: 8, train_loss:  0.0306\n",
      "tensor(-1.8647e-13)\n",
      "Epoch: 1, iter: 9, train_loss:  0.0306\n",
      "tensor(-1.1180e-13)\n",
      "Epoch: 1, iter: 10, train_loss:  0.0298\n",
      "tensor(-1.0946e-12)\n",
      "Epoch: 1, iter: 11, train_loss:  0.0312\n",
      "tensor(-1.4799e-12)\n",
      "Epoch: 1, iter: 12, train_loss:  0.0288\n",
      "tensor(-1.8284e-12)\n",
      "Epoch: 1, iter: 13, train_loss:  0.0280\n",
      "tensor(-9.1994e-13)\n",
      "Epoch: 1, iter: 14, train_loss:  0.0280\n",
      "tensor(-8.5417e-13)\n",
      "Epoch: 1, iter: 15, train_loss:  0.0317\n",
      "tensor(-6.0567e-13)\n",
      "Epoch: 1, iter: 16, train_loss:  0.0292\n",
      "tensor(9.3053e-14)\n",
      "Epoch: 1, iter: 17, train_loss:  0.0281\n",
      "tensor(-3.0250e-13)\n",
      "Epoch: 1, iter: 18, train_loss:  0.0284\n",
      "tensor(-4.2818e-13)\n",
      "Epoch: 1, iter: 19, train_loss:  0.0298\n",
      "tensor(-5.2720e-13)\n",
      "Epoch: 1, iter: 20, train_loss:  0.0280\n",
      "tensor(1.3297e-14)\n",
      "Epoch: 1, iter: 21, train_loss:  0.0279\n",
      "tensor(7.0146e-14)\n",
      "Epoch: 1, iter: 22, train_loss:  0.0269\n",
      "tensor(1.7022e-13)\n",
      "Epoch: 1, iter: 23, train_loss:  0.0275\n",
      "tensor(-2.4265e-13)\n",
      "Epoch: 1, iter: 24, train_loss:  0.0287\n",
      "tensor(-7.0751e-13)\n",
      "Epoch: 1, iter: 25, train_loss:  0.0265\n",
      "tensor(-1.3724e-13)\n",
      "Epoch: 1, iter: 26, train_loss:  0.0270\n",
      "tensor(-2.7160e-13)\n",
      "Epoch: 1, iter: 27, train_loss:  0.0255\n",
      "tensor(2.0751e-13)\n",
      "Epoch: 1, iter: 28, train_loss:  0.0268\n",
      "tensor(2.7649e-15)\n",
      "Epoch: 1, iter: 29, train_loss:  0.0267\n",
      "tensor(4.7366e-13)\n",
      "Epoch: 1, iter: 30, train_loss:  0.0280\n",
      "tensor(-6.2901e-14)\n",
      "Epoch: 1, iter: 31, train_loss:  0.0248\n",
      "tensor(9.7876e-13)\n",
      "Epoch: 1, iter: 32, train_loss:  0.0261\n",
      "tensor(1.0896e-12)\n",
      "Epoch: 1, iter: 33, train_loss:  0.0250\n",
      "tensor(-1.4214e-12)\n",
      "Epoch: 1, iter: 34, train_loss:  0.0251\n",
      "tensor(2.1006e-12)\n",
      "Epoch: 1, iter: 35, train_loss:  0.0244\n",
      "tensor(-2.6706e-12)\n",
      "Epoch: 1, iter: 36, train_loss:  0.0230\n",
      "tensor(3.6645e-12)\n",
      "Epoch: 1, iter: 37, train_loss:  0.0226\n",
      "tensor(3.1707e-12)\n",
      "Epoch: 1, iter: 38, train_loss:  0.0208\n",
      "tensor(-5.4638e-13)\n",
      "Epoch: 1, iter: 39, train_loss:  0.0215\n",
      "tensor(6.3201e-12)\n",
      "Epoch: 1, iter: 40, train_loss:  0.0205\n",
      "tensor(1.1730e-11)\n",
      "Epoch: 1, iter: 41, train_loss:  0.0208\n",
      "tensor(-1.8416e-11)\n",
      "Epoch: 1, iter: 42, train_loss:  0.0196\n",
      "tensor(-7.0152e-12)\n",
      "Epoch: 1, iter: 43, train_loss:  0.0191\n",
      "tensor(8.3675e-12)\n",
      "Epoch: 1, iter: 44, train_loss:  0.0188\n",
      "tensor(6.5893e-12)\n",
      "Epoch: 1, iter: 45, train_loss:  0.0185\n",
      "tensor(-6.5878e-14)\n",
      "Epoch: 1, iter: 46, train_loss:  0.0180\n",
      "tensor(-1.1345e-11)\n",
      "Epoch: 1, iter: 47, train_loss:  0.0182\n",
      "tensor(-1.7256e-11)\n",
      "Epoch: 1, iter: 48, train_loss:  0.0181\n",
      "tensor(1.6088e-11)\n",
      "Epoch: 1, iter: 49, train_loss:  0.0183\n",
      "tensor(1.1791e-11)\n",
      "Epoch: 1, iter: 50, train_loss:  0.0170\n",
      "tensor(-2.3004e-11)\n",
      "Epoch: 1, iter: 51, train_loss:  0.0181\n",
      "tensor(7.2186e-12)\n",
      "Epoch: 1, iter: 52, train_loss:  0.0170\n",
      "tensor(7.8152e-12)\n",
      "Epoch: 1, iter: 53, train_loss:  0.0187\n",
      "tensor(1.1226e-11)\n",
      "Epoch: 1, iter: 54, train_loss:  0.0183\n",
      "tensor(7.4737e-12)\n",
      "Epoch: 1, iter: 55, train_loss:  0.0174\n",
      "tensor(-1.0619e-11)\n",
      "Epoch: 1, iter: 56, train_loss:  0.0182\n",
      "tensor(7.6577e-13)\n",
      "Epoch: 1, iter: 57, train_loss:  0.0176\n",
      "tensor(1.9183e-12)\n",
      "Epoch: 1, iter: 58, train_loss:  0.0178\n",
      "tensor(1.3296e-11)\n",
      "Epoch: 1, iter: 59, train_loss:  0.0172\n",
      "tensor(1.1369e-11)\n",
      "Epoch: 1, iter: 60, train_loss:  0.0177\n",
      "tensor(-2.8396e-12)\n",
      "Epoch: 1, iter: 61, train_loss:  0.0176\n",
      "tensor(-7.3033e-12)\n",
      "Epoch: 1, iter: 62, train_loss:  0.0177\n",
      "tensor(-9.7446e-12)\n",
      "Epoch: 1, iter: 63, train_loss:  0.0170\n",
      "tensor(-7.6939e-12)\n",
      "Epoch: 1, iter: 64, train_loss:  0.0169\n",
      "tensor(-1.1316e-11)\n",
      "Epoch: 1, iter: 65, train_loss:  0.0185\n",
      "tensor(1.1679e-11)\n",
      "Epoch: 1, iter: 66, train_loss:  0.0157\n",
      "tensor(-7.5563e-12)\n",
      "Epoch: 1, iter: 67, train_loss:  0.0166\n",
      "tensor(5.6682e-12)\n",
      "Epoch: 1, iter: 68, train_loss:  0.0164\n",
      "tensor(-6.2365e-13)\n",
      "Epoch: 1, iter: 69, train_loss:  0.0169\n",
      "tensor(-5.9078e-12)\n",
      "Epoch: 1, iter: 70, train_loss:  0.0165\n",
      "tensor(-2.5015e-12)\n",
      "Epoch: 1, iter: 71, train_loss:  0.0158\n",
      "tensor(-4.7831e-13)\n",
      "Epoch: 1, iter: 72, train_loss:  0.0164\n",
      "tensor(1.6811e-11)\n",
      "Epoch: 1, iter: 73, train_loss:  0.0166\n",
      "tensor(6.0759e-13)\n",
      "Epoch: 1, iter: 74, train_loss:  0.0168\n",
      "tensor(6.6954e-12)\n",
      "Epoch: 1, iter: 75, train_loss:  0.0166\n",
      "tensor(-1.0425e-12)\n",
      "Epoch: 1, iter: 76, train_loss:  0.0166\n",
      "tensor(-4.7034e-12)\n",
      "Epoch: 1, iter: 77, train_loss:  0.0166\n",
      "tensor(-1.9388e-12)\n",
      "Epoch: 1, iter: 78, train_loss:  0.0159\n",
      "tensor(-1.7435e-12)\n",
      "Epoch: 1, iter: 79, train_loss:  0.0161\n",
      "tensor(-8.9193e-12)\n",
      "Epoch: 1, iter: 80, train_loss:  0.0161\n",
      "tensor(5.4754e-12)\n",
      "Epoch: 1, iter: 81, train_loss:  0.0170\n",
      "tensor(1.2079e-11)\n",
      "Epoch: 1, iter: 82, train_loss:  0.0161\n",
      "tensor(-1.9548e-11)\n",
      "Epoch: 1, iter: 83, train_loss:  0.0148\n",
      "tensor(-8.0620e-12)\n",
      "Epoch: 1, iter: 84, train_loss:  0.0162\n",
      "tensor(5.9662e-12)\n",
      "Epoch: 1, iter: 85, train_loss:  0.0145\n",
      "tensor(-8.6661e-12)\n",
      "Epoch: 1, iter: 86, train_loss:  0.0169\n",
      "tensor(8.9932e-12)\n",
      "Epoch: 1, iter: 87, train_loss:  0.0153\n",
      "tensor(-1.3634e-12)\n",
      "Epoch: 1, iter: 88, train_loss:  0.0150\n",
      "tensor(5.5913e-12)\n",
      "Epoch: 1, iter: 89, train_loss:  0.0152\n",
      "tensor(4.1504e-12)\n",
      "Epoch: 1, iter: 90, train_loss:  0.0158\n",
      "tensor(1.9129e-12)\n",
      "Epoch: 1, iter: 91, train_loss:  0.0159\n",
      "tensor(-2.2096e-12)\n",
      "Epoch: 1, iter: 92, train_loss:  0.0152\n",
      "tensor(-2.7746e-14)\n",
      "Epoch: 1, iter: 93, train_loss:  0.0154\n",
      "tensor(-3.2869e-12)\n",
      "Epoch: 1, iter: 94, train_loss:  0.0154\n",
      "tensor(-7.0099e-13)\n",
      "Epoch: 1, iter: 95, train_loss:  0.0151\n",
      "tensor(2.6247e-12)\n",
      "Epoch: 1, iter: 96, train_loss:  0.0153\n",
      "tensor(-1.1066e-12)\n",
      "Epoch: 1, iter: 97, train_loss:  0.0149\n",
      "tensor(2.8868e-12)\n",
      "Epoch: 1, iter: 98, train_loss:  0.0150\n",
      "tensor(-1.4521e-12)\n",
      "Epoch: 1, iter: 99, train_loss:  0.0152\n",
      "tensor(-9.8147e-12)\n",
      "Epoch: 1, iter: 100, train_loss:  0.0143\n",
      "tensor(1.5860e-12)\n",
      "Epoch: 1, iter: 101, train_loss:  0.0150\n",
      "tensor(5.2967e-12)\n",
      "Epoch: 1, iter: 102, train_loss:  0.0149\n",
      "tensor(-4.8587e-12)\n",
      "Epoch: 1, iter: 103, train_loss:  0.0148\n",
      "tensor(1.4284e-11)\n",
      "Epoch: 1, iter: 104, train_loss:  0.0148\n",
      "tensor(6.0596e-12)\n",
      "Epoch: 1, iter: 105, train_loss:  0.0147\n",
      "tensor(-1.7828e-12)\n",
      "Epoch: 1, iter: 106, train_loss:  0.0139\n",
      "tensor(-2.4201e-12)\n",
      "Epoch: 1, iter: 107, train_loss:  0.0146\n",
      "tensor(4.9858e-12)\n",
      "Epoch: 1, iter: 108, train_loss:  0.0147\n",
      "tensor(-7.7184e-12)\n",
      "Epoch: 1, iter: 109, train_loss:  0.0140\n",
      "tensor(-3.1891e-12)\n",
      "Epoch: 1, iter: 110, train_loss:  0.0151\n",
      "tensor(-2.9178e-12)\n",
      "Epoch: 1, iter: 111, train_loss:  0.0138\n",
      "tensor(4.1274e-12)\n",
      "Epoch: 1, iter: 112, train_loss:  0.0140\n",
      "tensor(2.9656e-12)\n",
      "Epoch: 1, iter: 113, train_loss:  0.0151\n",
      "tensor(-4.2820e-12)\n",
      "Epoch: 1, iter: 114, train_loss:  0.0138\n",
      "tensor(5.6825e-13)\n",
      "Epoch: 1, iter: 115, train_loss:  0.0148\n",
      "tensor(-6.1105e-12)\n",
      "Epoch: 1, iter: 116, train_loss:  0.0150\n",
      "tensor(-4.0206e-12)\n",
      "Epoch: 1, iter: 117, train_loss:  0.0152\n",
      "tensor(-7.8850e-12)\n",
      "Epoch: 1, iter: 118, train_loss:  0.0145\n",
      "tensor(4.2788e-12)\n",
      "Epoch: 1, iter: 119, train_loss:  0.0141\n",
      "tensor(5.8373e-12)\n",
      "Epoch: 1, iter: 120, train_loss:  0.0138\n",
      "tensor(-3.9129e-12)\n",
      "Epoch: 1, iter: 121, train_loss:  0.0138\n",
      "tensor(3.3848e-13)\n",
      "Epoch: 1, iter: 122, train_loss:  0.0169\n",
      "tensor(1.0121e-11)\n",
      "Epoch: 1, iter: 123, train_loss:  0.0151\n",
      "tensor(3.6758e-13)\n",
      "Epoch: 1, iter: 124, train_loss:  0.0149\n",
      "tensor(4.1770e-12)\n",
      "Epoch: 1, iter: 125, train_loss:  0.0154\n",
      "tensor(1.9705e-11)\n",
      "Epoch: 1, iter: 126, train_loss:  0.0145\n",
      "tensor(6.6672e-12)\n",
      "Epoch: 1, iter: 127, train_loss:  0.0150\n",
      "tensor(1.1389e-11)\n",
      "Epoch: 1, iter: 128, train_loss:  0.0142\n",
      "tensor(9.0387e-12)\n",
      "Epoch: 1, val_loss:  0.0149\n",
      "Epoch: 2, iter: 1, train_loss:  0.0145\n",
      "tensor(-1.1741e-11)\n",
      "Epoch: 2, iter: 2, train_loss:  0.0155\n",
      "tensor(-1.5166e-11)\n",
      "Epoch: 2, iter: 3, train_loss:  0.0154\n",
      "tensor(-1.2469e-11)\n",
      "Epoch: 2, iter: 4, train_loss:  0.0145\n",
      "tensor(-3.0270e-11)\n",
      "Epoch: 2, iter: 5, train_loss:  0.0148\n",
      "tensor(1.2552e-12)\n",
      "Epoch: 2, iter: 6, train_loss:  0.0140\n",
      "tensor(3.0532e-12)\n",
      "Epoch: 2, iter: 7, train_loss:  0.0145\n",
      "tensor(6.0337e-12)\n",
      "Epoch: 2, iter: 8, train_loss:  0.0135\n",
      "tensor(4.7907e-12)\n",
      "Epoch: 2, iter: 9, train_loss:  0.0144\n",
      "tensor(1.0311e-11)\n",
      "Epoch: 2, iter: 10, train_loss:  0.0153\n",
      "tensor(1.1551e-11)\n",
      "Epoch: 2, iter: 11, train_loss:  0.0144\n",
      "tensor(8.7670e-13)\n",
      "Epoch: 2, iter: 12, train_loss:  0.0145\n",
      "tensor(-1.4026e-12)\n",
      "Epoch: 2, iter: 13, train_loss:  0.0139\n",
      "tensor(-1.0761e-11)\n",
      "Epoch: 2, iter: 14, train_loss:  0.0149\n",
      "tensor(-1.5300e-12)\n",
      "Epoch: 2, iter: 15, train_loss:  0.0141\n",
      "tensor(-1.6090e-12)\n",
      "Epoch: 2, iter: 16, train_loss:  0.0130\n",
      "tensor(-9.4777e-12)\n",
      "Epoch: 2, iter: 17, train_loss:  0.0133\n",
      "tensor(-1.0967e-12)\n",
      "Epoch: 2, iter: 18, train_loss:  0.0139\n",
      "tensor(3.8747e-13)\n",
      "Epoch: 2, iter: 19, train_loss:  0.0135\n",
      "tensor(1.5537e-13)\n",
      "Epoch: 2, iter: 20, train_loss:  0.0133\n",
      "tensor(4.1397e-12)\n",
      "Epoch: 2, iter: 21, train_loss:  0.0142\n",
      "tensor(4.7317e-12)\n",
      "Epoch: 2, iter: 22, train_loss:  0.0132\n",
      "tensor(1.9378e-13)\n",
      "Epoch: 2, iter: 23, train_loss:  0.0145\n",
      "tensor(-2.2401e-12)\n",
      "Epoch: 2, iter: 24, train_loss:  0.0136\n",
      "tensor(-3.3965e-12)\n",
      "Epoch: 2, iter: 25, train_loss:  0.0138\n",
      "tensor(-1.8601e-12)\n",
      "Epoch: 2, iter: 26, train_loss:  0.0140\n",
      "tensor(-1.9033e-12)\n",
      "Epoch: 2, iter: 27, train_loss:  0.0137\n",
      "tensor(-3.7209e-12)\n",
      "Epoch: 2, iter: 28, train_loss:  0.0128\n",
      "tensor(4.1159e-12)\n",
      "Epoch: 2, iter: 29, train_loss:  0.0126\n",
      "tensor(1.5527e-13)\n",
      "Epoch: 2, iter: 30, train_loss:  0.0136\n",
      "tensor(7.7450e-13)\n",
      "Epoch: 2, iter: 31, train_loss:  0.0127\n",
      "tensor(-1.7058e-12)\n",
      "Epoch: 2, iter: 32, train_loss:  0.0139\n",
      "tensor(-4.6559e-13)\n",
      "Epoch: 2, iter: 33, train_loss:  0.0135\n",
      "tensor(2.6044e-12)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#----------------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#forward\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, y)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#----------------------------\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#backward\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 93\u001b[0m, in \u001b[0;36mmodel_task4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):    \n\u001b[0;32m---> 93\u001b[0m     output0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_DNN)\n\u001b[1;32m     94\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(output0)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_length)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/cardiac_challenge/.venv/lib64/python3.11/site-packages/torch/nn/functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#----------------------------\n",
    "#results\n",
    "history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "#----------------------------\n",
    "#\n",
    "for epoch in range(num_epochs):\n",
    "  #----------------------------\n",
    "  # train\n",
    "  model.train()\n",
    "  for i, (x, y) in enumerate(dataloder):\n",
    "    #----------------------------\n",
    "    #float32, grad==True\n",
    "    x = dataset.change_data_setting_to_train(x)\n",
    "    y = dataset.change_data_setting_to_train(y)\n",
    "    #----------------------------\n",
    "    #change the type\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    output = model(x)\n",
    "    loss = loss_func(output, y)\n",
    "    #----------------------------\n",
    "    #backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #----------------------------\n",
    "    #print & result\n",
    "    if (i+1) % n_print_train_result == 0:\n",
    "      print(f'Epoch: {epoch+1}, iter: {i+1}, train_loss: {loss: 0.4f}')\n",
    "      print(x.grad.mean())\n",
    "  history[\"train_loss\"].append(loss)\n",
    "\n",
    "  #----------------------------\n",
    "  # eval\n",
    "  if val_flag == True:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      #----------------------------\n",
    "      #forward\n",
    "      x, y = dataset.return_val_data()\n",
    "      #----------------------------\n",
    "      #float32, grad==True\n",
    "      x = dataset.change_data_setting_to_train(x)\n",
    "      y = dataset.change_data_setting_to_train(y)\n",
    "      #----------------------------\n",
    "      #change the type\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "      #----------------------------\n",
    "      #forward\n",
    "      output = model(x)\n",
    "      loss = loss_func(output, y)\n",
    "      #----------------------------\n",
    "      #print & result\n",
    "      history[\"val_loss\"].append(loss)\n",
    "      print(f'Epoch: {epoch+1}, val_loss: {loss: 0.4f}')\n",
    "  \n",
    "  #----------------------------\n",
    "  # scheduler\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------\n",
    "#make data (train)\n",
    "train_loss_tensor = torch.stack(history[\"train_loss\"])\n",
    "train_loss_np = train_loss_tensor.to('cpu').detach().numpy().copy()\n",
    "#----------------------------\n",
    "#make data (val)\n",
    "val_loss_tensor = torch.stack(history[\"val_loss\"])\n",
    "val_loss_np = val_loss_tensor.to('cpu').detach().numpy().copy()\n",
    "\n",
    "#----------------------------\n",
    "#plot\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(train_loss_np, color=\"black\",label=\"Train\")\n",
    "ax.plot(val_loss_np, color=\"maroon\",label=\"Validation\")\n",
    "#plot (setting)\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_xlabel(\"Epoch\", fontsize=30)\n",
    "ax.set_ylabel(\"MSE\", fontsize=30)\n",
    "ax.legend(fontsize=25, frameon=False)\n",
    "ax.set_ylim(0,0.02)\n",
    "#save, show\n",
    "plt.savefig(\"../figs/Task4/result_train/result_train.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "#----------------------------\n",
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    x, y = dataset.return_test_data()\n",
    "    #----------------------------\n",
    "    #float32, grad==True\n",
    "    x = dataset.change_data_setting_to_train(x)\n",
    "    y = dataset.change_data_setting_to_train(y)\n",
    "    #----------------------------\n",
    "    #change the type\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    output = model(x)\n",
    "    #----------------------------\n",
    "    #change to numpy\n",
    "    output = output.to('cpu').detach().numpy().copy().flatten()\n",
    "    y = y.to('cpu').detach().numpy().copy().flatten()\n",
    "    loss_MSE = mean_squared_error(output, y)\n",
    "    loss_R2 = r2_score(output, y)\n",
    "    #----------------------------\n",
    "    #print loss\n",
    "    print(\"MSE: \", loss_MSE)  \n",
    "    print(\"R2: \", loss_R2)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_test (true/pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score # \n",
    "from sklearn.metrics import mean_absolute_error #  (MAE)\n",
    "from sklearn.metrics import mean_squared_error #  (MSE)\n",
    "#----------------\n",
    "def plot_true_predict_from_y(y_predict_list:pd.DataFrame, y_true_list:pd.DataFrame,\n",
    "                            title:str, path_save=False) -> None:\n",
    "    #----------------\n",
    "    #calc score\n",
    "    r = np.corrcoef(y_true_list, y_predict_list)[0][1]\n",
    "    R2 = r2_score(y_true=y_true_list, y_pred=y_predict_list) # (R2) #https://bellcurve.jp/statistics/course/9706.html\n",
    "    MAE = mean_absolute_error(y_true=y_true_list, y_pred=y_predict_list) # (MAE)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_true=y_true_list, y_pred=y_predict_list)) # (RMSE)\n",
    "    \n",
    "    #----------------\n",
    "    #fig, ax\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    #----------------\n",
    "    #plot scatter\n",
    "    #ax.scatter(x=y_predict_list, y=y_true_list, s=40, c=\"black\", marker=\"o\", zorder=10)\n",
    "    #ax.plot(y_predict_list, y_true_list, c=\"grey\", marker='.', linestyle=\"\", ms=0.005, zorder=10, alpha=0.7)\n",
    "    sns.regplot(x=y_predict_list, y=y_true_list, color=\"grey\", marker=\".\",scatter=False,  ax=ax, scatter_kws={'s':0.005})\n",
    "    #----------------\n",
    "    #plot \n",
    "    x=np.linspace( min(min(y_true_list),min(y_predict_list)), max(max(y_true_list),max(y_predict_list)), 10) #list\n",
    "    y=x\n",
    "    ax.plot(x, y, color = \"black\")\n",
    "    #----------------\n",
    "    #plot text\n",
    "    plt.text(x=0.5, y=0.94, \n",
    "             s=\"$r$={0}, $R^2$={1}, $MAE$={2}, $RMSE$={3}\".format(\"{:.2f}\".format(r),\n",
    "                                                                 \"{:.2f}\".format(R2),\n",
    "                                                                \"{:.2f}\".format(MAE),\n",
    "                                                                \"{:.2f}\".format(RMSE)), \n",
    "             fontdict=dict(fontsize=25, color=\"black\"), ha='center', transform=ax.transAxes,\n",
    "             zorder=20)\n",
    "    #----------------\n",
    "    #setting\n",
    "    ax.tick_params(labelsize = 20)#\n",
    "    ax.set_xlabel(\"True\",fontsize=30)\n",
    "    ax.set_ylabel(\"Predict\",fontsize=30)\n",
    "    plt.title(\"{0}\".format(title), fontsize=30)\n",
    "    #----------------\n",
    "    #save\n",
    "    if path_save != False:\n",
    "        plt.savefig(path_save, bbox_inches='tight')\n",
    "    #----------------\n",
    "    #show\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    x, y = dataset.return_test_data()\n",
    "    #----------------------------\n",
    "    #float32, grad==True\n",
    "    x = dataset.change_data_setting_to_train(x)\n",
    "    y = dataset.change_data_setting_to_train(y)\n",
    "    #----------------------------\n",
    "    #change the type\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    output = model(x)\n",
    "    #----------------------------\n",
    "    #change to numpy\n",
    "    output = output.to('cpu').detach().numpy().copy().flatten() * 150 - 100\n",
    "    y = y.to('cpu').detach().numpy().copy().flatten() * 150 - 100\n",
    "    #----------------------------\n",
    "    #plot\n",
    "    plot_true_predict_from_y(y_predict_list=output, y_true_list=y, title=\"\", path_save=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_test (sample_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_VmDatas_Task4(VmData_true, VmData_pred):\n",
    "    num_timesteps = 500\n",
    "    plt.figure(figsize=(18, 9))\n",
    "\n",
    "    for count, i in enumerate(range(VmData_true.shape[0])):\n",
    "        plt.subplot(8, 10, count + 1)\n",
    "        plt.plot(VmData_true[i,0:num_timesteps])\n",
    "        plt.plot(VmData_pred[i,0:num_timesteps])\n",
    "        plt.title(f'i = {i}')\n",
    "        plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "        # plt.xlabel('msec')\n",
    "        # plt.ylabel('mV')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "#----------------------------\n",
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    x, y = dataset.return_test_data()\n",
    "    #----------------------------\n",
    "    #float32, grad==True\n",
    "    x = dataset.change_data_setting_to_train(x)\n",
    "    y = dataset.change_data_setting_to_train(y)\n",
    "    #----------------------------\n",
    "    #change the type\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    output = model(x)\n",
    "    #----------------------------\n",
    "    #change to numpy\n",
    "    output = output.to('cpu').detach().numpy().copy() * 150 - 100\n",
    "    y = y.to('cpu').detach().numpy().copy() * 150 - 100\n",
    "    #----------------------------\n",
    "    #plot\n",
    "    for cnt, (data_true, data_pred) in enumerate(zip(y, output)):\n",
    "        plot_VmDatas_Task4(data_true, data_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_test (sample_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_VmDatas_Task4_each(VmData, title):\n",
    "    # plot the VmData\n",
    "    plt.imshow(VmData, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "    plt.title('Activation Time')\n",
    "    cbar = plt.colorbar()\n",
    "    plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "    plt.minorticks_on()\n",
    "    # not xticks\n",
    "    #plt.xticks([])\n",
    "    plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.title(\"{0}\".format(title), fontsize=20)\n",
    "    plt.xlabel(\"Time\",fontsize=15)\n",
    "    plt.ylabel(\"Number of Activation Map\",fontsize=15)\n",
    "    cbar.set_label('Value', fontsize=15, rotation=270, labelpad=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# eval\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    x, y = dataset.return_test_data()\n",
    "    #----------------------------\n",
    "    #float32, grad==True\n",
    "    x = dataset.change_data_setting_to_train(x)\n",
    "    y = dataset.change_data_setting_to_train(y)\n",
    "    #----------------------------\n",
    "    #change the type\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    #----------------------------\n",
    "    #forward\n",
    "    output = model(x)\n",
    "    #----------------------------\n",
    "    #change to numpy\n",
    "    output = output.to('cpu').detach().numpy().copy() * 150 - 100\n",
    "    y = y.to('cpu').detach().numpy().copy() * 150 - 100\n",
    "    #----------------------------\n",
    "    #plot\n",
    "    for cnt, (data_true, data_pred) in enumerate(zip(y, output)):\n",
    "        plot_VmDatas_Task4_each(VmData=data_true, title=\"True\")\n",
    "        plot_VmDatas_Task4_each(VmData=data_pred, title=\"Predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test (CustomDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Union\n",
    "\n",
    "#---------------------------------------------\n",
    "# custom dataset\n",
    "#https://discuss.pytorch.org/t/custom-data-loader-for-big-data/129361\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path_dir_X:str, path_dir_Y:str, n_test:Union[int,float], n_val:Union[int,float], batch_size:int): # n_test -> float:ratio of test, int:number of test\n",
    "        #-----------------\n",
    "        # batch_size\n",
    "        self.batch_size = batch_size\n",
    "        # path_dir_X, path_dir_Y\n",
    "        self.path_dir_X = path_dir_X\n",
    "        self.path_dir_Y = path_dir_Y\n",
    "        # list_file_name_all\n",
    "        self.list_file_name_all = os.listdir(path_dir_X)\n",
    "        # n_data_all\n",
    "        self.n_data_all = len(self.list_file_name_all)\n",
    "        #check\n",
    "        if len(os.listdir(path_dir_X)) != len(os.listdir(path_dir_Y)):\n",
    "            raise ValueError(\"error!!!\")\n",
    "        if len(set(os.listdir(path_dir_X)) - set(os.listdir(path_dir_Y))) != 0:\n",
    "            raise ValueError(\"error!!!\")\n",
    "        #-----------------\n",
    "        # suffle\n",
    "        random.shuffle(self.list_file_name_all)\n",
    "        #-----------------\n",
    "        # n_test\n",
    "        if type(n_test)==int:\n",
    "            self.n_test = n_test\n",
    "        elif type(n_test)==float:\n",
    "            self.n_test = int(len(self.list_file_name_all)*n_test)\n",
    "        else:\n",
    "            raise ValueError(\"error!!!\")\n",
    "        # n_val\n",
    "        if type(n_val)==int:\n",
    "            self.n_val = n_val\n",
    "        elif type(n_val)==float:\n",
    "            self.n_val = int(len(self.list_file_name_all)*n_val)\n",
    "        else:\n",
    "            raise ValueError(\"error!!!\")\n",
    "        #check\n",
    "        if self.n_data_all <= self.n_test+self.n_val:\n",
    "            raise ValueError(\"error!!!\")\n",
    "        #-----------------\n",
    "        # list_file_name_test / _val / _train\n",
    "        self.list_file_name_test = self.list_file_name_all[:self.n_test]\n",
    "        self.list_file_name_val = self.list_file_name_all[self.n_test:self.n_test+self.n_val]\n",
    "        self.list_file_name_train = self.list_file_name_all[self.n_test+self.n_val:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_file_name_train)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        return self.getdata(list_file_name=self.list_file_name_train, index=x)\n",
    "    \n",
    "    def getdata(self, list_file_name, index):\n",
    "        #file_name\n",
    "        file_name = list_file_name[index]\n",
    "        #data_X\n",
    "        path_file_X = \"{0}/{1}\".format(self.path_dir_X, file_name)\n",
    "        data_X = np.load(path_file_X, allow_pickle=True)\n",
    "        data_X = torch.from_numpy(data_X).to(torch.float32)\n",
    "        #data_Y\n",
    "        path_file_Y = \"{0}/{1}\".format(self.path_dir_Y, file_name)\n",
    "        data_Y = np.load(path_file_Y, allow_pickle=True)\n",
    "        data_Y = torch.from_numpy(data_Y).to(torch.float32)\n",
    "        #return\n",
    "        return data_X, data_Y\n",
    "    \n",
    "    def return_n_data_all(self):\n",
    "        return self.n_data_all\n",
    "    \n",
    "    def return_n_test(self):\n",
    "        return self.n_test\n",
    "    \n",
    "    def return_n_val(self):\n",
    "        return self.n_val\n",
    "    \n",
    "    def return_n_train(self):\n",
    "        return self.n_data_all - self.n_val - self.n_test\n",
    "    \n",
    "    def return_batch_size(self):\n",
    "        return self.batch_size\n",
    "    \n",
    "    def return_shape_X(self):\n",
    "        data_sample = self.getdata(self.list_file_name_all, 0)[0]\n",
    "        return data_sample.shape\n",
    "    \n",
    "    def return_shape_Y(self):\n",
    "        data_sample = self.getdata(self.list_file_name_all, 0)[1]\n",
    "        return data_sample.shape\n",
    "    \n",
    "    def return_test_data(self):\n",
    "        #https://www.tutorialspoint.com/how-to-join-tensors-in-pytorch\n",
    "        data_X_test = torch.stack([self.getdata(self.list_file_name_test, i)[0] for i in range(self.n_test)])\n",
    "        data_Y_test = torch.stack([self.getdata(self.list_file_name_test, i)[1] for i in range(self.n_test)])\n",
    "        return data_X_test, data_Y_test\n",
    "    \n",
    "    def return_val_data(self):\n",
    "        #https://www.tutorialspoint.com/how-to-join-tensors-in-pytorch\n",
    "        data_X_val = torch.stack([self.getdata(self.list_file_name_val, i)[0] for i in range(self.n_val)])\n",
    "        data_Y_val = torch.stack([self.getdata(self.list_file_name_val, i)[1] for i in range(self.n_val)])\n",
    "        return data_X_val, data_Y_val\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "#var\n",
    "path_dir_X = \"../data_X\"\n",
    "path_dir_Y = \"../data_Y_Task3\"\n",
    "n_test = 100\n",
    "n_val = 100\n",
    "batch_size = 10000\n",
    "\n",
    "#---------------------------------------------\n",
    "#instance\n",
    "dataset = CustomDataset(path_dir_X=path_dir_X, path_dir_Y=path_dir_Y, n_test=n_test, n_val=n_val, batch_size=batch_size)\n",
    "dataloder = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data_X, data_Y) in enumerate(dataloder):\n",
    "   # print(data_X.shape, data_Y.shape)\n",
    "   print(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.return_n_data_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.return_n_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.return_n_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.return_val_data()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.return_test_data()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset.return_val_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image. \n",
    "        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last block which does not include a max-pooling layer.\n",
    "        # -------\n",
    "        # input: 572x572x3\n",
    "        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # output: 570x570x64\n",
    "        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 568x568x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n",
    "\n",
    "        # input: 284x284x64\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 282x282x128\n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 280x280x128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
    "\n",
    "        # input: 140x140x128\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 138x138x256\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 136x136x256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
    "\n",
    "        # input: 68x68x256\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 66x66x512\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 64x64x512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
    "\n",
    "        # input: 32x32x512\n",
    "        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # output: 30x30x1024\n",
    "        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) # output: 28x28x1024\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "\n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1(nn.Module):\n",
    "    def __init__(self, in_channels, in_length, out_channels, out_length):\n",
    "        super().__init__()\n",
    "        #-----------------------------------\n",
    "        #Conv1d\n",
    "        in_channels_inner_0 = in_channels; in_length_inner_0 = in_length\n",
    "        kernel_size=2; stride=1; padding=1; dilation=1; \n",
    "        out_channels_inner_0 = 30; out_length_inner_0 = (in_length_inner_0+2*padding-dilation*(kernel_size-1)-1)/stride+1\n",
    "        self.conv1d = nn.Conv1d(in_channels=in_channels_inner_0, out_channels=out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        #-----------------------------------\n",
    "        #DNN\n",
    "        in_channels_inner_1 = out_channels_inner_0*out_length_inner_0; out_channels_inner_1 = out_channels\n",
    "\n",
    "        #-----------------------------------\n",
    "        #layer0\n",
    "        self.layer0 = nn.Sequential(\n",
    "            #-----------------------------------\n",
    "            nn.Conv1d(in_channels=in_channels_inner_0, out_channels=out_channels_inner_0, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation),\n",
    "            nn.relu(),\n",
    "            nn.BatchNorm1d(out_channels_inner_0*out_length_inner_0),\n",
    "            #-----------------------------------\n",
    "            nn.Linear(in_channels_inner_1, out_channels_inner_1),\n",
    "            nn.relu(),\n",
    "            nn.Sigmoid()\n",
    "            #nn.BatchNorm1d(self.params_size+self.features_size),\n",
    "            #nn.BatchNorm1d(3),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output0 = self.layer0(x)\n",
    "        return output0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/sshuv/items/79d9364b8675fdc080cf\n",
    "#https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "#https://cvml-expertguide.net/terms/dl/layers/convolution-layer/\n",
    "\n",
    "\n",
    "#-----------------------------------\n",
    "#n_batch=10; n_feature=6; n_time=10; \n",
    "n_batch=1000; in_channels=75; in_length=500; \n",
    "x = torch.rand(n_batch, in_channels, in_length)\n",
    "\n",
    "#-----------------------------------\n",
    "in_channels=in_channels; out_channels=30; kernel_size=3; stride=1; padding=1; dilation=1; \n",
    "conv1d = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "\n",
    "#-----------------------------------\n",
    "n_batch=n_batch; out_channels=out_channels; out_length=int((in_length+2*padding-dilation*(kernel_size-1)-1)/stride+1)\n",
    "y = conv1d(x)\n",
    "print(n_batch, out_channels, out_length)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5, requires_grad=True)\n",
    "mse_loss = nn.MSELoss()\n",
    "output = mse_loss(input, target) #mse_loss(input, target), mse_loss(target, input)\n",
    "output.backward()\n",
    "\n",
    "print('input: ', input)\n",
    "print('target: ', target)\n",
    "print('output: ', output)\n",
    "print(input.grad)\n",
    "print(target.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "mse_loss = nn.MSELoss()\n",
    "output = mse_loss(input, target)\n",
    "print('output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mse_loss(input.view(15), target.view(15))\n",
    "output.backward()\n",
    "print('output: ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(5, 2)\n",
    "output = m(input)\n",
    "output = m(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.regplot(x = [1,2,3,4,5],\n",
    "            y = [4,5,6,4,7], \n",
    "            color=\"grey\", marker=\".\",scatter=False, scatter_kws={'s':0.005}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
