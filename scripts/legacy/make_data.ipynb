{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\"data_hearts_dd_0p2\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_1_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_2_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl_gkr\",\n",
    "            \"data_hearts_dd_0p2_geo_act_3_bcl_gkr_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_1_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_1_bcl_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_2_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_2_bcl_I\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_3_bcl\",\n",
    "            \"data_hearts_dd_0p2_geo_inn_act_3_bcl_I\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Y_Task3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "for cnt, dir_name in enumerate(dir_list):\n",
    "    os.makedirs(\"../VmData_Activation/{}\".format(dir_name), exist_ok=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make VmData_Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../rawdatas/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == \"VmData\":\n",
    "            #-----------------\n",
    "            #ndarray_write\n",
    "            ndarray_write = np.array([])\n",
    "            #-----------------\n",
    "            #load data\n",
    "            ndarray_VmData = np.load(\"../rawdatas/{0}/{1}\".format(dir_name,file_name))\n",
    "            #-----------------\n",
    "            #activation_time\n",
    "            for i in range(ndarray_VmData.shape[1]):\n",
    "                #activation_time\n",
    "                activation_time = np.where(ndarray_VmData[:,i]>0)[0][0]\n",
    "                #print(ndarray_VmData[:20,i])\n",
    "                #print(activation_time)\n",
    "                #append\n",
    "                ndarray_write = np.append(ndarray_write, activation_time)\n",
    "            #-----------------\n",
    "            #reshape ndarray_write\n",
    "            # (75,) -> (1, 75)\n",
    "            #-----------------\n",
    "            #file_name_write\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            #-----------------\n",
    "            #save\n",
    "            np.save(\"../Data_Y_Task3/{0}\".format(file_name_write), ndarray_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ndarray_VmData_Activation = np.load('../Data_Y_Task3/VmData_hearts_dd_0p2_volunteer.v1_pattern.0.npy')\n",
    "print(ndarray_VmData_Activation.shape)\n",
    "print(ndarray_VmData_Activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_X, Data_Y_Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "for _, dir_name in enumerate(dir_list):\n",
    "    #-----------------\n",
    "    #list_file_name\n",
    "    list_file_name = os.listdir(\"../rawdatas/{}\".format(dir_name))\n",
    "    #-----------------\n",
    "    #processing√ü\n",
    "    for _, file_name in enumerate(list_file_name):\n",
    "        #-----------------\n",
    "        #first_string\n",
    "        first_string = file_name.split(\"_\")[0]\n",
    "        #-----------------\n",
    "        #path_before\n",
    "        path_before = \"../rawdatas/{0}/{1}\".format(dir_name,file_name)\n",
    "        #-----------------\n",
    "        #check file & processing\n",
    "        if first_string == \"VmData\":\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            path_after = \"../Data_Y_Task4/{}\".format(file_name_write)\n",
    "            shutil.copyfile(path_before, path_after)\n",
    "        elif first_string == \"pECGData\":\n",
    "            file_name_write = \"_\".join([str(elem) for elem in file_name.split(\"_\")[1:]])\n",
    "            path_after = \"../Data_X/{}\".format(file_name_write)\n",
    "            shutil.copyfile(path_before, path_after)\n",
    "        elif first_string == \".bash\":\n",
    "            pass\n",
    "        else:\n",
    "            print(first_string)\n",
    "            raise ValueError(\"error!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check # of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
